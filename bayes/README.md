# 朴素贝叶斯分类

## 1. 模型 

### 1.1条件概率

 贝叶斯分类器属于生成模型，源于贝叶斯学派的观点 --- 随机事件发生概率取决于历史经验数据的，也就说将要发生的一件事情是过去某一件事情是相关联的。用什么数学语言可以描述事件与事件之间的关联程度呢？答案是条件概率。A、B为非独立事件，在事件A发生的条件下事件B发生的概率为
$$
P(B | A) = \frac{P(A∩B) }{P(A)}
$$

```
+--------------+
|   A          |			事件A与B的文氏图
|     +--------——-------+
|     |   A∩B  |        |
|     |        |   B    |
|     +--------——-------+
|              |
+--------------+
```

反过来，在事件B发生的条件下事件A发生的概率为
$$
P(A | B) = \frac{P(A∩B)} {P(B)}
$$
 所以P(A∩B) = P(A | B) * P(B) = P(B | A) * P(A)

### 1.2 独立同分布假设

可以得出贝叶斯条件概率公式：

P(A | B) = P(B | A)  * P(A) / P(B)

P(B | A) = P(A | B)  * P(B) / P(A)

推广：

已知事件X = (x1, x2, x3, ... , xn)在事件Y = (y1, y2, y3, ... , yn)发生的条件下概率为

P(X | Y) = P(X = x1 | Y) * P(X = x1 , X = x2 | Y) * P(X = x1, X = x2, X = x3 | Y) ... P(X = x1, X = x2,..., X = xn | Y) 

由此可见求解P(X | Y)的计算量是非常大的，但如果假设事件x1, x2, x3 , ... , xn是相互独立，可得

P(X | Y) = P(X = x1 | Y) * P(X = x2 | Y) * P(X = x3 | Y) ... P(X = xn | Y) 

那么计算量将大幅下降，这便是贝叶斯分类器对数据特征做独立同分布的假设。

所以P(Y | X) = P(X = x1 | Y) * P(X = x2 | Y) * P(X = x3 | Y) ... P(X = xn | Y)  / P(X)

### 1.3分类问题

​	分类问题可以理解为分类器从已知的数据集中学习到了其中的规律再对未知数据进行分类，条件概率衡量了数据特征与标签类的关联程度。



## 2.策略

### 2.1极大似然估计

后验概率最大化

### 2.2贝叶斯估计

解决0概率的问题

## 3.算法

**a. 样本数据转化为特征向量**

**b. 计算先验概率**

**c. 根据未知的样本数据计算后验概率**

**d. 在所有样本标签中选取后验概率最大的标签作为分类标签**

